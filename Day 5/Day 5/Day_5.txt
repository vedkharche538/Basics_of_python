# K-Means Clustering


# Importing the libraries
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd


# Importing the dataset (Bivariate Data Set with 3 Clusters)
dataset = pd.read_csv('xclara.csv')

features = dataset.iloc[:, [0, 1]].values


# There is no Categorial data
# There is no Missing data 
# There is no different scale data


#Scatter all these data points on the matplotlib
# It seems as a human that it will have 3 clusters or groups
plt.scatter(features[:,0], features[:,1])
plt.show()


# Fitting K-Means to the dataset using 3 clusters
from sklearn.cluster import KMeans
# Since we have seen the visual, we have told the algo to make 3 cluster
kmeans = KMeans(n_clusters = 3, init = 'k-means++')

pred_cluster = kmeans.fit_predict(features) # We have only passed features 

print(pred_cluster) # Its the cluster id with 0 1 and 2 



# How to find which points from features falls with cluster id 0
print(features)
print(pred_cluster)
print(pred_cluster == 0  )
# will gives a True False Array, we will use boolean indexing concept
print(features[pred_cluster == 0])
print(len(features[pred_cluster == 0]))


# How to find which points from features falls with cluster id 1
print(features)
print(pred_cluster == 1  )
# will gives a True False Array, we will use boolean indexing concept
print(features[pred_cluster == 1])
print(len(features[pred_cluster == 1]))
print(len(features[pred_cluster == 0]))
print(len(features[pred_cluster == 2]))


# How to find which points from features falls with cluster id 2
print(features)
print(pred_cluster == 2 )
# will gives a True False Array, we will use boolean indexing concept
print(features[pred_cluster == 2])
print(len(features[pred_cluster == 2]))


# Will print V1
print(features[pred_cluster == 0, 0])  # 0 is for V1

# Will print V2
print(features[pred_cluster == 0, 1])  # 1 is for V2


# Visualising the clusters
#plt.scatter(features[:,0][y_kmeans == 0], features[:,1][y_kmeans == 0], s = 100, c = 'red', label = 'Cluster 1')
plt.scatter(features[pred_cluster == 0, 0], features[pred_cluster == 0, 1], c = 'blue', label = 'Cluster 1')
plt.scatter(features[pred_cluster == 1, 0], features[pred_cluster == 1, 1], c = 'red', label = 'Cluster 2')
plt.scatter(features[pred_cluster == 2, 0], features[pred_cluster == 2, 1], c = 'green', label = 'Cluster 3')


# Centroid of the clusters 
print(kmeans.cluster_centers_)  # There are three points for 3 centroid

print(kmeans.cluster_centers_[:, 0]) # x 
print(kmeans.cluster_centers_[:, 1]) # y 

# Central Location of the Cluster == Centroid
# Centroid = Avg of x coordinate and Avg of y coordinate for lets assume Cluster 1
plt.scatter(features[pred_cluster == 0, 0], features[pred_cluster == 0, 1], c = 'blue', label = 'Cluster 1')
plt.scatter(features[pred_cluster == 1, 0], features[pred_cluster == 1, 1], c = 'red', label = 'Cluster 2')
plt.scatter(features[pred_cluster == 2, 0], features[pred_cluster == 2, 1], c = 'green', label = 'Cluster 3')
plt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], c = 'yellow', label = 'Centroids')



plt.title('Clusters of datapoints')
plt.xlabel('X Cordindates')
plt.ylabel('Y Cordinates')
plt.legend()
plt.show()



# How to find the optimal number of clusters ??
# Understand a concept WCSS ( Within Cluster Sum of Squares )

# Outer Loop to iterate through the number of clusters
for i in range(1, 11):
    print(i)
    # Within each iteration we need to now find the sum
    
    
# Using the elbow method to find the optimal number of clusters
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd

dataset = pd.read_csv('xclara.csv')

features = dataset.iloc[:, [0, 1]].values
   

from sklearn.cluster import KMeans

wcss = []
for i in range(1, 11):
    kmeans = KMeans(n_clusters = i, init = 'k-means++', random_state = 0)
    kmeans.fit(features)  # we have not used the fit_predict
    #print("Cluster " + str(i) +  "  =  " + str(kmeans.inertia_))
    wcss.append(kmeans.inertia_)     # ( calculates wcss for a cluster )
    
print(wcss)

#Now plot it        
plt.plot(range(1, 11), wcss)
plt.title('Elbow Method')
plt.xlabel('Number of Clusters')
plt.ylabel('WCSS')
plt.show()


# Code Challenges

"""
Q1. (Create a program that fulfills the following specification.)
deliveryfleet.csv


Import deliveryfleet.csv file

Here we need Two driver features: mean distance driven per day (Distance_feature) 
and the mean percentage of time a driver was >5 mph over the speed limit (speeding_feature).

Perform K-means clustering to distinguish urban drivers and rural drivers.
Perform K-means clustering again to further distinguish speeding drivers 
from those who follow speed limits, in addition to the rural vs. urban division.
Label accordingly for the 4 groups.


"""

